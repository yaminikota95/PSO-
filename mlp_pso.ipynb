{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>MLP training using PSO</h1></center>\n",
    "<center><h2>Objective: Train the MLP using the Particle Swarm Optimization algorithm for finding weights and biases.</h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "# Import PySwarms\n",
    "import pyswarms as ps\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "data = load_iris()\n",
    "\n",
    "# Store the features as X and the labels as y\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward propagation of the Single Hidden Layer Feed Forward Network with:\n",
    "### Input data dimension = 4;\n",
    "### Hidden layer dimension = 20;\n",
    "### Number of classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "def forward_prop(params):\n",
    "    \"\"\"Forward propagation as objective function\n",
    "\n",
    "    This computes for the forward propagation of the neural network, as\n",
    "    well as the loss. It receives a set of parameters that must be\n",
    "    rolled-back into the corresponding weights and biases.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    params: np.ndarray\n",
    "        The dimensions should include an unrolled version of the\n",
    "        weights and biases.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The computed negative log-likelihood loss given the parameters\n",
    "    \"\"\"\n",
    "    # Neural network architecture\n",
    "    n_inputs = 4\n",
    "    n_hidden = 20\n",
    "    n_classes = 3\n",
    "\n",
    "    # Roll-back the weights and biases\n",
    "    W1 = params[0:80].reshape((n_inputs,n_hidden))\n",
    "    b1 = params[80:100].reshape((n_hidden,))\n",
    "    W2 = params[100:160].reshape((n_hidden,n_classes))\n",
    "    b2 = params[160:163].reshape((n_classes,))\n",
    "\n",
    "    # Perform forward propagation\n",
    "    z1 = X.dot(W1) + b1  # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1)     # Activation in Layer 1\n",
    "    z2 = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
    "    logits = z2          # Logits for Layer 2\n",
    "\n",
    "    # Compute for the softmax of the logits\n",
    "    exp_scores = np.exp(logits)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute for the negative log likelihood\n",
    "    N = 150 # Number of samples\n",
    "    corect_logprobs = -np.log(probs[range(N), y])\n",
    "    loss = np.sum(corect_logprobs) / N\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function: Error from negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(x):\n",
    "    \"\"\"Higher-level method to do forward_prop in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [forward_prop(x[i]) for i in range(n_particles)]\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global best PSO algorithm for finding the optimal weights and biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 11:09:39,445 - pyswarms.single.global_best - INFO - Optimize for 1000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|█████████████████████████████████████████████████████████|1000/1000, best_cost=0.0383\n",
      "2020-02-23 11:09:58,629 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.03828562888861999, best pos: [ 2.70000414e-01  1.09725913e+00  1.97964842e+00 -1.33152029e-02\n",
      " -8.28573961e-02  8.40499757e-01 -1.01932135e-01  2.86622194e-01\n",
      "  1.32289640e+00 -3.05055239e-01 -1.40236652e-01  2.68665422e-01\n",
      "  3.14637885e-01  6.56860289e-01 -1.46792360e+00 -5.26579488e-02\n",
      "  8.82050289e-01 -3.00764704e-02 -1.42874057e-01 -8.25965772e-01\n",
      " -7.29540369e-01  3.23015620e-01 -3.53272998e-01 -1.05470920e-01\n",
      " -1.25965185e+00  9.12792075e-02  1.16912576e+00  1.88137214e+00\n",
      " -9.06006058e-01  8.61098627e-02  3.12868859e-01  9.55791842e-01\n",
      "  1.56219963e+00  2.59951714e+00  1.53260982e+00  9.04517580e-01\n",
      "  1.37225624e+00  6.16479477e-01 -1.44546808e+00 -1.04196680e-01\n",
      "  8.59042080e-01 -7.99466384e-01  1.75628721e-01  1.80204358e+00\n",
      "  1.06227105e+00  1.62345365e-01 -1.72718397e+00  1.80620298e-01\n",
      "  3.05534560e-01  5.84038739e-01  2.27322134e+00 -1.25202234e+00\n",
      "  3.54467520e-01  4.29685481e-01  1.29286994e+00 -1.26084299e+00\n",
      " -1.22988511e-01  1.04997816e+00  1.09494077e-01  4.17518927e-01\n",
      "  1.80463933e+00  1.72426307e+00 -1.12491277e-01  1.03020105e+00\n",
      "  2.63168070e+00  1.22479077e+00  3.23540455e-01  5.39016058e-01\n",
      " -1.10940157e+00  1.60515694e+00 -4.16895546e+00 -4.65319457e-01\n",
      "  1.92117970e+00  3.62575726e-01  2.88342000e-01  8.30992351e-01\n",
      " -2.58043131e-01  1.41530854e+00  9.75812456e-02  4.69826397e+00\n",
      " -3.33213207e+00  4.54720528e-01  6.03852454e-02 -1.79008371e+00\n",
      " -5.60663625e+00  1.10208394e+00 -2.10138076e-01 -7.90965344e-01\n",
      "  8.63216048e-01  4.86967622e-02  1.35808070e+00  5.36198297e+00\n",
      "  1.01452276e+00  1.26507338e+00 -5.64815293e-01  8.40060488e-03\n",
      "  1.87779549e+00 -4.67390530e-01 -6.83824962e-01 -4.65299750e-01\n",
      " -9.60383498e-01  3.98066750e-01  3.71643911e-01 -6.70840959e-02\n",
      "  1.81696083e-01 -8.11010612e-01  3.12727531e-01 -1.32089006e+00\n",
      "  2.98580581e-01  1.23898910e+00 -9.77435538e-01 -1.56011454e-02\n",
      " -5.26413782e-01 -5.04151967e+00  1.91426480e+00  9.75882446e-01\n",
      "  1.96322189e+00  5.69222654e-01  1.10884877e+00 -1.15295024e+00\n",
      " -3.78087988e-01 -4.05930257e-01  4.36725860e-01  7.81329352e-01\n",
      "  6.47617665e-01 -4.10804899e-01 -2.86709491e-01  1.05355303e+00\n",
      "  3.73186765e+00  7.48830088e-01 -3.96810470e-01 -2.65545767e+00\n",
      "  2.95644474e+00 -9.75930291e-02 -1.27668888e+00 -6.19567512e-01\n",
      "  6.45601445e-01 -8.49145635e-01 -2.40839969e+00  3.59039918e-01\n",
      "  1.57157952e+00 -1.32336727e+00 -9.34985201e-01 -5.39229948e+00\n",
      "  1.91911160e+00 -3.11614003e-01 -4.83673144e-01  1.06588422e-01\n",
      "  2.88967684e+00  1.46615657e-01  7.30199464e-01  2.01363411e-01\n",
      "  4.27440755e-01 -8.22046091e-02  1.68019202e-01  1.39663291e-01\n",
      "  2.58975691e-01 -1.64405731e+01  1.70888184e+00 -3.80970804e+00\n",
      " -8.72182628e-01  7.73533629e-01  2.46736612e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialize swarm\n",
    "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}  #weights for the current velocity, self best position and global best position\n",
    "\n",
    "# Call instance of PSO\n",
    "dimensions = (4 * 20) + (20 * 3) + 20 + 3\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimensions, options=options)\n",
    "\n",
    "# Perform optimization\n",
    "cost, pos = optimizer.optimize(f, iters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the accuracy using the obtained weights and biases from the PSO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, pos):\n",
    "    \"\"\"\n",
    "    Use the trained weights to perform class predictions.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    X: numpy.ndarray\n",
    "        Input Iris dataset\n",
    "    pos: numpy.ndarray\n",
    "        Position matrix found by the swarm. Will be rolled\n",
    "        into weights and biases.\n",
    "    \"\"\"\n",
    "    # Neural network architecture\n",
    "    n_inputs = 4\n",
    "    n_hidden = 20\n",
    "    n_classes = 3\n",
    "\n",
    "    # Roll-back the weights and biases\n",
    "    W1 = pos[0:80].reshape((n_inputs,n_hidden))\n",
    "    b1 = pos[80:100].reshape((n_hidden,))\n",
    "    W2 = pos[100:160].reshape((n_hidden,n_classes))\n",
    "    b2 = pos[160:163].reshape((n_classes,))\n",
    "\n",
    "    # Perform forward propagation\n",
    "    z1 = X.dot(W1) + b1  # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1)     # Activation in Layer 1\n",
    "    z2 = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
    "    logits = z2          # Logits for Layer 2\n",
    "\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predict(X, pos) == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reference: https://pyswarms.readthedocs.io/en/latest/examples/usecases/train_neural_network.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
